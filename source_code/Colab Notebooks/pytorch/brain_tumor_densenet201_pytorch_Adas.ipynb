{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "brain_tumor_densenet201_pytorch_Adas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ccf310894a94a9696df7ac1f8d66a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52ac42fee7e64c4fbfc33138229377fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b806ce3054934161ae4b872cd73c36ac",
              "IPY_MODEL_fabc6798d78e4c56a9d2f84937837577"
            ]
          }
        },
        "52ac42fee7e64c4fbfc33138229377fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b806ce3054934161ae4b872cd73c36ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ce54e5e094d492ca212087f7e1ac182",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 81131730,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 81131730,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37241406a77e4a87922a23a76a3cf659"
          }
        },
        "fabc6798d78e4c56a9d2f84937837577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb926ee270ce4152968ff52b7c653d45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.4M/77.4M [00:01&lt;00:00, 59.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bd31080701f44c1bc9a0566a545b644"
          }
        },
        "4ce54e5e094d492ca212087f7e1ac182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37241406a77e4a87922a23a76a3cf659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb926ee270ce4152968ff52b7c653d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bd31080701f44c1bc9a0566a545b644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al_XWgRp3EzB",
        "outputId": "5b0691ca-b023-4e88-ce75-2aebb368b421"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPMeqQO6AP2D",
        "outputId": "2532dd64-ebf4-4453-ea9f-6d7f632df431"
      },
      "source": [
        "%cd /content/drive/My Drive/Adas/src\n",
        "from adas import Adas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Adas/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrQMAMh7ARMZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms\n",
        "import helper\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_IymEbSAWFo"
      },
      "source": [
        "IMAGE_SIZE = 256\n",
        "batch_size = 20\n",
        "\n",
        "DATADIR_TRAIN = \"/content/drive/My Drive/DetectBrainTumor/data_15062021/T2_Train/\"\n",
        "DATADIR_VAL = \"/content/drive/My Drive/DetectBrainTumor/data_15062021/T2_Val/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dG28e-KICv6"
      },
      "source": [
        "# Applying Transforms to the Data\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JuOKAOLAi0X"
      },
      "source": [
        "train_data = datasets.ImageFolder(DATADIR_TRAIN, transform=train_transform)                                       \n",
        "val_data = datasets.ImageFolder(DATADIR_VAL, transform=test_transform)\n",
        "\n",
        "#Data Loading\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOZ-WlKeJUnb"
      },
      "source": [
        "classes = ('YES', 'NO')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTT7H1l_NvJr"
      },
      "source": [
        "train_data_size = len(train_data)\n",
        "test_data_size = len(val_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP2vIpVTXMPE"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWHwvjeWOVSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5ccf310894a94a9696df7ac1f8d66a83",
            "52ac42fee7e64c4fbfc33138229377fa",
            "b806ce3054934161ae4b872cd73c36ac",
            "fabc6798d78e4c56a9d2f84937837577",
            "4ce54e5e094d492ca212087f7e1ac182",
            "37241406a77e4a87922a23a76a3cf659",
            "fb926ee270ce4152968ff52b7c653d45",
            "5bd31080701f44c1bc9a0566a545b644"
          ]
        },
        "outputId": "a3b0b06f-8f6d-4ccd-87df-6a7736da4deb"
      },
      "source": [
        "# Load pretrained DenseNet201 Model\n",
        "model_class = models.densenet201(pretrained=True)\n",
        "\n",
        "# Freeze model parameters\n",
        "# for param in model_class.parameters():\n",
        "#     param.requires_grad = False\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ccf310894a94a9696df7ac1f8d66a83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=81131730.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de-uV2riupyc"
      },
      "source": [
        "# Change the final layer of DenseNet201 Model for Transfer Learning\n",
        "classifier_input = model_class.classifier.in_features\n",
        "\n",
        "model_class.classifier = nn.Sequential(\n",
        "    nn.Linear(classifier_input, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, 2), # Since 100 possible outputs\n",
        "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
        ")\n",
        "\n",
        "# Convert model to be used on GPU\n",
        "model_class = model_class.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx6C95OqFFT1"
      },
      "source": [
        "def train_and_validate(model, scheduler, loss_criterion, optimizer, epochs):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_loss = 100000.0\n",
        "    best_epoch = None\n",
        "    flag = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "        \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(val_loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "                # if not j%100:\n",
        "                #   print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            best_epoch = epoch\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_valid_loss = valid_loss/test_data_size \n",
        "        avg_valid_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, Validation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
        "\n",
        "        #reduce lr\n",
        "        \n",
        "        if avg_valid_acc*100 > 90:\n",
        "          flag = 1\n",
        "\n",
        "        if flag == 1:\n",
        "          scheduler.step(avg_valid_loss)\n",
        "        \n",
        "        print('Epoch-{0} learning rate: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        # Save if the model has best accuracy till now\n",
        "        # torch.save(model, 'model_'+str(epoch)+'.pt')\n",
        "        # optimizer.epoch_step(epoch)       \n",
        "    return model, history, best_epoch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkM6wkzKp3Ea",
        "outputId": "b156a275-1fa1-46ff-e5ab-4e8fb52ba08b"
      },
      "source": [
        "# Define Optimizer and Loss Function\n",
        "loss_func = nn.NLLLoss()\n",
        "optimizer = Adas(params=list(model_class.parameters()), lr=7e-3, beta = 0.95)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR6dTBifOhoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b530b8b-632a-4f4a-c276-cd51e5ed66aa"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# trained_model, history, best_epoch = train_and_validate(model_class, loss_func, optimizer, num_epochs)\n",
        "\n",
        "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20,35], gamma=0.1)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=torch.exp(-0.1))\n",
        "\n",
        "# lambda1 = lambda epoch: torch.exp(-1) ** epoch\n",
        "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor= 0.8, patience=3, threshold=0.0001, threshold_mode='abs')\n",
        "\n",
        "trained_model, history, best_epoch = train_and_validate(model_class, scheduler, loss_func, optimizer, num_epochs)\n",
        "\n",
        "end = time.time()\n",
        "# torch.save(history, 'history.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 001, Training: Loss - 0.6525, Accuracy - 61.7466%, Validation : Loss - 0.6353, Accuracy - 70.2929%, Time: 187.6640s\n",
            "Epoch-0 learning rate: 0.007\n",
            "Epoch: 2/100\n",
            "Epoch : 002, Training: Loss - 0.5053, Accuracy - 81.0578%, Validation : Loss - 0.5361, Accuracy - 71.9665%, Time: 22.8725s\n",
            "Epoch-1 learning rate: 0.007\n",
            "Epoch: 3/100\n",
            "Epoch : 003, Training: Loss - 0.3629, Accuracy - 87.0849%, Validation : Loss - 0.4113, Accuracy - 79.9163%, Time: 22.9685s\n",
            "Epoch-2 learning rate: 0.007\n",
            "Epoch: 4/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HigTVpI3JjHv"
      },
      "source": [
        "print(\"Thoi gian training: \",end-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLogHqND8-R4"
      },
      "source": [
        "loss_train = []\n",
        "loss_val = []\n",
        "acc_train = []\n",
        "acc_val = []\n",
        "\n",
        "for i in range(len(history)):\n",
        "  loss_train.append(history[i][0])\n",
        "  loss_val.append(history[i][1])\n",
        "  acc_train.append(history[i][2])\n",
        "  acc_val.append(history[i][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB0-ZXLqI5fZ"
      },
      "source": [
        "# summarize history for accuracy\n",
        "\n",
        "fig,a =  plt.subplots(1, 2, figsize=(16,7))\n",
        "a[0].plot(acc_train)\n",
        "a[0].plot(acc_val)\n",
        "a[0].set_title('model accuracy')\n",
        "a[0].set_ylabel('accuracy')\n",
        "a[0].set_xlabel('epoch')\n",
        "a[0].legend(['train', 'val'], loc='upper left')\n",
        "# summarize history for loss for epoch\n",
        "# plt.figure(figsize=(10,10))\n",
        "a[1].plot(loss_train)\n",
        "a[1].plot(loss_val)\n",
        "a[1].set_title('model loss')\n",
        "a[1].set_ylabel('loss')\n",
        "a[1].set_xlabel('epoch')\n",
        "a[1].legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5m4BELqQFxX"
      },
      "source": [
        "# # Specify a path\n",
        "# dir_model = '/content/drive/My Drive/DetectBrainTumor/model/pytorch/densenet201_adas.pt'\n",
        "# # Save\n",
        "# torch.save(trained_model, dir_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgC45tYcQL2G"
      },
      "source": [
        "# from PIL import Image\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Load\n",
        "# model_densenet = torch.load(dir_model)\n",
        "# model_densenet.eval()\n",
        "\n",
        "# test_transform = transforms.Compose([\n",
        "#         transforms.Resize(size=256),\n",
        "#         transforms.CenterCrop(size=224),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406],\n",
        "#                              [0.229, 0.224, 0.225])\n",
        "#     ])\n",
        "\n",
        "\n",
        "# path = \"/content/drive/My Drive/DetectBrainTumor/data_05052021/\"\n",
        "# path = \"/content/drive/My Drive/DetectBrainTumor/data_24062021/\"\n",
        "\n",
        "# test_data = datasets.ImageFolder(path, transform=test_transform)  \n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "# # image = Image.open(Path('/content/drive/My Drive/DetectBrainTumor/data_05052021/NO/IMG-0001-00012.jpg'))\n",
        "# # image = Image.open('/content/drive/My Drive/DetectBrainTumor/data_05052021/NO/IMG-0001-00012.jpg')\n",
        "# # input = test_transform(image)\n",
        "# # input = input.unsquueeze(0)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.to(device)\n",
        "#         labels = labels.to(device)\n",
        "#         outputs = model_densenet(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         # print(outputs)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "          \n",
        "#     print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}